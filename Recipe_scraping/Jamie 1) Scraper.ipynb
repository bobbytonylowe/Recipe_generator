{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\robert.lowe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from urllib.request import Request, urlopen\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "nltk.download('stopwords')\n",
    "from scrapy.http import TextResponse\n",
    "import datetime\n",
    "from scrapy import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cracker ravioli'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jamieoliver.com/recipes/pasta-recipes/cracker-ravioli/'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"h1\", class_=\"hidden-xs\")\n",
    "title.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 hours'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jamieoliver.com/recipes/pasta-recipes/cracker-ravioli/'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"div\", class_=\"recipe-detail time\")\n",
    "title = title.text\n",
    "title = title.replace('\\nCooks In', '')\n",
    "title = title.replace('                                                    ', '')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Serves 6 or 12 as a starter'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jamieoliver.com/recipes/pasta-recipes/cracker-ravioli/'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"div\", class_=\"recipe-detail serves\")\n",
    "title = title.text\n",
    "title = title.replace('\\nCooks In', '')\n",
    "title = title.replace('                                                    ', '')\n",
    "title = title.replace('\\n', '')\n",
    "title = title.replace('    ','')\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<img alt=\"Cracker ravioli\" src=\"//img.jamieoliver.com/jamieoliver/recipe-database/xtra_med/63841221.jpg?tr=w-414,\"/>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jamieoliver.com/recipes/pasta-recipes/cracker-ravioli/'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"img\", class_=\"\")\n",
    "\n",
    "title = str(title)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//img.jamieoliver.com/jamieoliver/recipe-database/xtra_med/90303518.jpg?tr=w-414'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jamieoliver.com/recipes/egg-recipes/italian-baked-eggs/'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"img\", class_=\"\")\n",
    "\n",
    "title = str(title)\n",
    "title = title.split('src=\"')\n",
    "title[1].replace(',\"/>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"//img.jamieoliver.com/jamieoliver/recipe-database/xtra_med/90303518.jpg?tr=w-414\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= title[1].replace(',\"/>',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'800 g broccoli and cauliflower,  olive oil, 1 heaped teaspoon baharat (see tip), 4 cloves of garlic, 250 g puy lentils, 1 litre organic vegetable stock, 1  fresh bay leaf, 2  lemons,  extra virgin olive oil, 100 g walnuts, 1 large bunch of mixed soft herbs (parsley mint chervil), 250 g halloumi cheese, 2 tablespoons runny honey'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.jamieoliver.com/recipes/vegetables-recipes/roasted-brassicas-with-puy-lentils-halloumi/'\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "webpage = urlopen(req).read()\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "recipes = []\n",
    "for p in soup.findAll(\"ul\", class_=\"ingred-list\"):\n",
    "    if p.find(\"li\", class_=\"ingred-heading\"):\n",
    "        pass\n",
    "    recipes.append(p.get_text())\n",
    "y = [re.sub(\",\", \"\", x) for x in recipes]\n",
    "y = \",\".join(y)\n",
    "y = y.replace('    ', ' ')\n",
    "y = y.replace('    ', ' ')\n",
    "y = y.replace('    ', ' ')\n",
    "y = y.replace('    ', ' ')\n",
    "y = y.replace('    ', ' ')\n",
    "y = y.replace('   ', ' ')\n",
    "y = y.replace('\\n\\n',', ')\n",
    "y = y.replace(' TO SERVE, ',' ')\n",
    "y = y.replace('  \\n, ','')\n",
    "y = y.replace('  \\n', '')\n",
    "y = y.replace('  ,  ', ', ')\n",
    "y = y.replace('   ',' ')\n",
    "#y= y.replace('  ', ' ')\n",
    "\n",
    "y = y[3:]\n",
    "mylist = y.split(',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "title = soup.findAll(\"li\", class_=\"ingred-heading\")\n",
    "#title = soup.findAll(\"ul\", class_=\"ingred-list\")\n",
    "title = [x.text for x in title]\n",
    "clean = []\n",
    "for z in title:   \n",
    "    b = z.replace('\\n                    ', '').replace('                  ','')\n",
    "    clean.append(b)\n",
    "#ingred_heading = soup.findAll(\"ul\", class_=\"ingred-heading\")\n",
    "title1 = [x.replace('                ', '') for x in clean]\n",
    "\n",
    "\n",
    "ingredients = [x for x in mylist if x not in title1]\n",
    "(',').join(ingredients)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jamie(url):\n",
    "    try:\n",
    "        req = Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36'})\n",
    "        webpage = urlopen(req).read()\n",
    "        soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "\n",
    "        # Title \n",
    "        recipe = soup.find(\"h1\", class_=\"hidden-xs\")\n",
    "        recipe = recipe.text\n",
    "        \n",
    "        # Feeds\n",
    "        Feeds = soup.find(\"div\", class_=\"recipe-detail serves\")\n",
    "        Feeds = Feeds.text\n",
    "        Feeds = Feeds.replace('\\nCooks In', '')\n",
    "        Feeds = Feeds.replace('                                                    ', '')\n",
    "        Feeds = Feeds.replace('\\n', '')\n",
    "        Feeds = Feeds.replace('    ','')\n",
    "        \n",
    "        # Time\n",
    "        Time = soup.find(\"div\", class_=\"recipe-detail time\")\n",
    "        Time = Time.text\n",
    "        Time = Time.replace('\\nCooks In', '')\n",
    "        Time = Time.replace('                                                    ', '')\n",
    "        \n",
    "        # Ingredients \n",
    "        recipes = []\n",
    "        for p in soup.findAll(\"ul\", class_=\"ingred-list\"):\n",
    "            if p.find(\"li\", class_=\"ingred-heading\"):\n",
    "                pass\n",
    "            recipes.append(p.get_text())\n",
    "        y = [re.sub(\",\", \"\", x) for x in recipes]\n",
    "        y = \",\".join(y)\n",
    "        y = y.replace('    ', ' ')\n",
    "        y = y.replace('    ', ' ')\n",
    "        y = y.replace('    ', ' ')\n",
    "        y = y.replace('    ', ' ')\n",
    "        y = y.replace('    ', ' ')\n",
    "        y = y.replace('   ', ' ')\n",
    "        y = y.replace('\\n\\n',', ')\n",
    "        y = y.replace(' TO SERVE, ',' ')\n",
    "        y = y.replace('  \\n, ','')\n",
    "        y = y.replace('  \\n', '')\n",
    "        y = y.replace('  ,  ', ', ')\n",
    "        y = y.replace('   ',' ')\n",
    "        #y= y.replace('  ', ' ')\n",
    "\n",
    "        y = y[3:]\n",
    "        mylist = y.split(',')\n",
    "        \n",
    "        #ignore this link\n",
    "        title = soup.findAll(\"li\", class_=\"ingred-heading\")\n",
    "        title = [x.text for x in title]\n",
    "        clean = []\n",
    "        for z in title:   \n",
    "            b = z.replace('\\n                    ', '').replace('                  ','')\n",
    "            clean.append(b)\n",
    "        title1 = [x.replace('                ', '') for x in clean]\n",
    "        ingredients = [x for x in mylist if x not in title1]\n",
    "        ingredients = (',').join(ingredients)\n",
    "\n",
    "        # Number of Ingredients\n",
    "        ingred_count = ingredients.count(',')\n",
    "        ingred_count = ingred_count + 1\n",
    "        \n",
    "        # image \n",
    "        image = soup.find(\"img\", class_=\"\")\n",
    "\n",
    "        image = str(image)\n",
    "        image = image.split('src=\"')\n",
    "        image = image[1].replace(',\"/>','')\n",
    "\n",
    "        # Create a dataframe\n",
    "        d = {\n",
    "            'Title': recipe, \n",
    "             \"Serving\": Feeds, \n",
    "             'Cook_time': Time, \n",
    "             'Ingredients': ingredients,\n",
    "            \"Number of ingredients\" : ingred_count,\n",
    "            \"Image_link\": image,\n",
    "             \"Link\": url\n",
    "\n",
    "            }\n",
    "        df = pd.DataFrame(data=d, index=[0])\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
